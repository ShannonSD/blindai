{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c9f250e",
   "metadata": {},
   "source": [
    "# About this example\n",
    "\n",
    "This example shows how you can deploy ALBERT model to analyze confidential text for sentiment analysis. The model will be left untrained for demonstration purposes. We could finetune it on positive/negative samples before deploying it.\n",
    "\n",
    "By using BlindAI, people can send data for the AI to analyze sensitive text without having to fear privacy leaks.\n",
    "\n",
    "ALBERT is a state of the art Transformers model for NLP. You can learn more about it on this [Hugging Face page](https://huggingface.co/docs/transformers/model_doc/albert).\n",
    "\n",
    "More information on this use case can be found on our blog post [Deploy Transformers models with confidentiality](https://blog.mithrilsecurity.io/transformers-with-confidentiality/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334419ad",
   "metadata": {},
   "source": [
    "# Installing dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb9cfaa",
   "metadata": {},
   "source": [
    "Install the dependencies this example needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[onnx] torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008593de",
   "metadata": {},
   "source": [
    "Install the latest version of BlindAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc9033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install blindai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553770d3",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed8e595",
   "metadata": {},
   "source": [
    "In this first step we will export a standard Hugging Face ALBERT model to an ONNX file, as BlindAI accepts only ONNX files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6fcc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "model_name = \"albert-base-v2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "text = \"Paris is the [MASK] of France.\"\n",
    "tokenizer_output = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "input_ids = tokenizer_output[\"input_ids\"]\n",
    "attention_mask = tokenizer_output[\"attention_mask\"]\n",
    "token_type_ids = tokenizer_output[\"token_type_ids\"]\n",
    "\n",
    "dynamic_axes = {\n",
    "    0: \"batch\",\n",
    "    1: \"seq\",\n",
    "}\n",
    "\n",
    "output_dir = \"./albert\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (input_ids, attention_mask, token_type_ids),\n",
    "    os.path.join(output_dir, \"model.onnx\"),\n",
    "    input_names=[\"input_ids\", \"attention_mask\", \"token_type_ids\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": dynamic_axes,\n",
    "        \"attention_mask\": dynamic_axes,\n",
    "        \"token_type_ids\": dynamic_axes,\n",
    "        \"logits\": dynamic_axes,\n",
    "    },\n",
    "    opset_version=13,\n",
    ")\n",
    "\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd8d46a",
   "metadata": {},
   "source": [
    "# Deployment on BlindAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5ad38",
   "metadata": {},
   "source": [
    "Please make sure the **server is running**. To launch the server, refer to the [Launching the server](https://docs.mithrilsecurity.io/getting-started/quick-start/run-the-blindai-server) documentation page. \n",
    "\n",
    "If you have followed the steps and have the Docker image ready, this mean you simply have to run `docker run -it -p 50051:50051 -p 50052:50052 mithrilsecuritysas/blindai-server-sim:latest`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68573c53",
   "metadata": {},
   "source": [
    "So the first thing we need to do is to connect securely to the BlindAI server instance. Here we will use simulation mode for ease of use. This means that we do not leverage the hardware security propertiers of secure enclaves, but we do not need to run the Docker image with a specific hardware.\n",
    "\n",
    "If you wish to run this example in hardware mode, you need to prepare the `host_server.pem` and `policy.toml` files. Learn more on the [Deploy on Hardware](https://docs.mithrilsecurity.io/getting-started/deploy-on-hardware) documentation page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ddc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import blindai.client \n",
    "from blindai.client import ModelDatumType\n",
    "\n",
    "# Launch client\n",
    "\n",
    "# Simulation mode\n",
    "client = blindai.client.connect(addr=\"localhost\", simulation=True)\n",
    "\n",
    "# Hardware mode\n",
    "# client.connect_server(addr=\"localhost\", policy=\"./policy.toml\", certificate=\"./host_server.pem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889d5725",
   "metadata": {},
   "source": [
    "Then, upload the model inside the BlindAI server. This simply means uploading the ONNX file created before.\n",
    "\n",
    "When uploading the model, we have to precise the shape of the input and the data type. In this case, because we use Transformers model with tokens, we simply need to send the indices of the tokens, i.e. integers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77e835b",
   "metadata": {},
   "source": [
    "And in the case of a multiple input model like ALBERT, we have to provide each input and its datum type in a list just as provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb82e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_inputs = [\n",
    "    [input_ids.shape, ModelDatumType.I64],\n",
    "    [token_type_ids.shape, ModelDatumType.I64],\n",
    "    [attention_mask.shape, ModelDatumType.I64]\n",
    "]\n",
    "\n",
    "tensor_outputs = ModelDatumType.F32\n",
    "response = client.upload_model(model=\"./albert/model.onnx\", tensor_inputs=tensor_inputs, tensor_outputs=tensor_outputs)\n",
    "model_id = response.model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df5c14e",
   "metadata": {},
   "source": [
    "# Sending data for confidential prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f17a9f",
   "metadata": {},
   "source": [
    "Now it's time to check it's working live!\n",
    "\n",
    "We will just prepare the inputs for the model inside the secure enclave of BlindAI to process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37386717",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text)[\"input_ids\"]\n",
    "token_type = tokenizer(text)[\"token_type_ids\"]\n",
    "attention = tokenizer(text)[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c49e3e",
   "metadata": {},
   "source": [
    "Now we can get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b4612",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.run_model(model_id, [inputs, token_type, attention], sign=True)\n",
    "print(response.output[:20]) # Reducing the output if it's very long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e609cfb",
   "metadata": {},
   "source": [
    "Here we can compare the results against the original prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c535d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputs = model(torch.tensor(inputs).unsqueeze(0), torch.tensor(\n",
    "    token_type).unsqueeze(0), torch.tensor(attention).unsqueeze(0)).logits.detach()\n",
    "\n",
    "print(outputs[0][0].tolist()[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1d65f",
   "metadata": {},
   "source": [
    "Et voila! We have been able to apply a start of the art model of NLP, without ever having to show the data in clear to the people operating the service!\n",
    "\n",
    "If you have liked this example, do not hesitate to drop a star on our [GitHub](https://github.com/mithril-security/blindai) and chat with us on our [Discord](https://discord.gg/TxEHagpWd4)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base-3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9dd108426c773819c9e297fb8aecd1b719ea0feb0bd9933b28738f20856ce7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
